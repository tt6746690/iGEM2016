ccopy_reg
_reconstructor
p1
(c__main__
LogisticRegression
p2
c__builtin__
object
p3
NtRp4
(dp5
S'b'
g1
(ctheano.tensor.sharedvar
TensorSharedVariable
p6
g3
NtRp7
(dp8
S'auto_name'
p9
S'auto_22'
p10
sS'index'
p11
NsS'tag'
p12
(itheano.gof.utils
scratchpad
p13
(dp14
S'trace'
p15
(lp16
(lp17
(S'sampleLogit.py'
p18
I416
S'<module>'
p19
S'sgd_optimization_mnist()'
tp20
a(S'sampleLogit.py'
p21
I243
S'sgd_optimization_mnist'
p22
S'classifier = LogisticRegression(input=x, n_in=FEATURE_COUNT, n_out=2)'
tp23
a(S'sampleLogit.py'
p24
I62
S'__init__'
p25
S'borrow=True'
tp26
aasbsS'container'
p27
g1
(ctheano.gof.link
Container
p28
g3
NtRp29
(dp30
S'name'
p31
S'b'
sS'storage'
p32
(lp33
cnumpy.core.multiarray
_reconstruct
p34
(cnumpy
ndarray
p35
(I0
tS'b'
tRp36
(I1
(I2
tcnumpy
dtype
p37
(S'f8'
I0
I1
tRp38
(I3
S'<'
NNNI-1
I-1
I0
tbI00
S'\xbfE^\xed\x8d\x05\xcf\xbfgE^\xed\x8d\x05\xcf?'
tbasS'strict'
p39
I00
sS'readonly'
p40
I00
sS'type'
p41
g1
(ctheano.tensor.type
TensorType
p42
g3
NtRp43
(dp44
S'broadcastable'
p45
(I00
tp46
sS'dtype'
p47
S'float64'
p48
sS'numpy_dtype'
p49
g38
sS'sparse_grad'
p50
I00
sg31
NsbsS'allow_downcast'
p51
Nsbsg31
S'b'
sS'owner'
p52
Nsg41
g43
sbsS'y_pred'
p53
g1
(ctheano.tensor.var
TensorVariable
p54
g3
NtRp55
(dp56
g9
S'auto_32'
p57
sg11
I1
sg12
(itheano.gof.utils
scratchpad
p58
(dp59
g15
(lp60
(lp61
(g18
I416
g19
S'sgd_optimization_mnist()'
tp62
a(g21
I243
g22
S'classifier = LogisticRegression(input=x, n_in=FEATURE_COUNT, n_out=2)'
tp63
a(g24
I77
g25
S'self.y_pred = T.argmax(self.p_y_given_x, axis=1)'
tp64
aasbsg31
S'argmax'
p65
sg52
g1
(ctheano.gof.graph
Apply
p66
g3
NtRp67
(dp68
S'inputs'
p69
(lp70
g1
(g54
g3
NtRp71
(dp72
g9
S'auto_29'
p73
sg11
I0
sg12
(itheano.gof.utils
scratchpad
p74
(dp75
g15
(lp76
(lp77
(g18
I416
g19
S'sgd_optimization_mnist()'
tp78
a(g21
I243
g22
S'classifier = LogisticRegression(input=x, n_in=FEATURE_COUNT, n_out=2)'
tp79
a(g24
I73
g25
S'self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)'
tp80
aasbsg31
Nsg52
g1
(g66
g3
NtRp81
(dp82
g69
(lp83
g1
(g54
g3
NtRp84
(dp85
g9
S'auto_28'
p86
sg11
I0
sg12
(itheano.gof.utils
scratchpad
p87
(dp88
g15
(lp89
(lp90
(g18
I416
g19
S'sgd_optimization_mnist()'
tp91
a(g21
I243
g22
S'classifier = LogisticRegression(input=x, n_in=FEATURE_COUNT, n_out=2)'
tp92
a(g24
I73
g25
S'self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)'
tp93
aasbsg31
Nsg52
g1
(g66
g3
NtRp94
(dp95
g69
(lp96
g1
(g54
g3
NtRp97
(dp98
g9
S'auto_23'
p99
sg11
I0
sg12
(itheano.gof.utils
scratchpad
p100
(dp101
g15
(lp102
(lp103
(g18
I416
g19
S'sgd_optimization_mnist()'
tp104
a(g21
I243
g22
S'classifier = LogisticRegression(input=x, n_in=FEATURE_COUNT, n_out=2)'
tp105
a(g24
I73
g25
S'self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)'
tp106
aasbsg31
Nsg52
g1
(g66
g3
NtRp107
(dp108
g69
(lp109
g1
(g54
g3
NtRp110
(dp111
g9
S'auto_19'
p112
sg11
Nsg12
(itheano.gof.utils
scratchpad
p113
(dp114
g15
(lp115
(lp116
(g18
I416
g19
S'sgd_optimization_mnist()'
tp117
a(g21
I238
g22
S"x = T.matrix('x')  # data, presented as rasterized images"
tp118
aasbsg31
S'x'
sg52
Nsg41
g1
(g42
g3
NtRp119
(dp120
g45
(I00
I00
tp121
sg47
S'float64'
p122
sg49
g38
sg50
I00
sg31
Nsbsbag1
(g6
g3
NtRp123
(dp124
g9
S'auto_21'
p125
sg11
Nsg12
(itheano.gof.utils
scratchpad
p126
(dp127
g15
(lp128
(lp129
(g18
I416
g19
S'sgd_optimization_mnist()'
tp130
a(g21
I243
g22
S'classifier = LogisticRegression(input=x, n_in=FEATURE_COUNT, n_out=2)'
tp131
a(g24
I53
g25
S'borrow=True'
tp132
aasbsg27
g1
(g28
g3
NtRp133
(dp134
g31
S'W'
sg32
(lp135
g34
(g35
(I0
tS'b'
tRp136
(I1
(I226
I2
tg38
I00
S'\xc1\x1cjW?\xeb\xf8?\xc1\x1cjW?\xeb\xf8\xbf@JP\xa1\xd6\x0b\xb4\xbf7JP\xa1\xd6\x0b\xb4?\xb9\xe1\x1f;\xdd\xb2\xd6\xbf\xb4\xe1\x1f;\xdd\xb2\xd6?\xbc\xc1\x14\x1e\xedM\xd2?\xb5\xc1\x14\x1e\xedM\xd2\xbf\xd0\x96\x90\xe7\x91Y\xf2?\xce\x96\x90\xe7\x91Y\xf2\xbf\xd2\xe8\xaf\xfd\x01}\x00\xc0\xd2\xe8\xaf\xfd\x01}\x00@Q\xb1\xefe{\x81\xe6?P\xb1\xefe{\x81\xe6\xbf\x0c"\xdf\xfd6\x9a\xc9\xbf\x00"\xdf\xfd6\x9a\xc9?`\xf2\x9eB\x0c\x84\x8d?\xe1\xf2\x9eB\x0c\x84\x8d\xbf]R\x03\x8d\xe1\x1b\xd4?_R\x03\x8d\xe1\x1b\xd4\xbf\xb0]A\xc2\xae]\xf2?\xae]A\xc2\xae]\xf2\xbf\xdb\xc8\x8a\xf7\xc1\x05\xef\xbf\xda\xc8\x8a\xf7\xc1\x05\xef?\xf1\x9f\xd1\xf8\xb5\xff\xee?\xef\x9f\xd1\xf8\xb5\xff\xee\xbf[\xd9\xda\xff\\)\xf1\xbfY\xd9\xda\xff\\)\xf1?\x1f\xf5\x03\xf5@p\xe5\xbf\x1f\xf5\x03\xf5@p\xe5?\xed9N \x0c\x8b\xd0\xbf\xe39N \x0c\x8b\xd0?3\xfa\x84i\xee\x8e\xc1?9\xfa\x84i\xee\x8e\xc1\xbf\xffs\xcf\xf6\x83\x1a\xb3\xbf\xe9s\xcf\xf6\x83\x1a\xb3?\xad\xf9\x1ay\x97<\xfb\xbf\xac\xf9\x1ay\x97<\xfb?\x95t\xbb\xdf\xe3?\xf3\xbf\x95t\xbb\xdf\xe3?\xf3?\xa7^0\xcb\x85\xcc\xde?\x9f^0\xcb\x85\xcc\xde\xbfKv\x0cg)-\xf2?Mv\x0cg)-\xf2\xbf\xfd\xa0ES\xfet\xe7\xbf\xfb\xa0ES\xfet\xe7?\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\xa8t\x01\xaf\xe7\x91\xd0?\xaat\x01\xaf\xe7\x91\xd0\xbfO!\xd9\x07xk\xd9?Q!\xd9\x07xk\xd9\xbfS\x13\xe3\xc6\x99#\xdd\xbfV\x13\xe3\xc6\x99#\xdd?\xf7>\xe6i\xf7~\x94\xbf\xea>\xe6i\xf7~\x94?\xe8i\xa5A\x99[\xef\xbf\xeai\xa5A\x99[\xef?\x0e\xbd\xaf\xc8\xacc\xc5\xbf\x10\xbd\xaf\xc8\xacc\xc5?xz\xbe!\xa0\xdd\xb2\xbfzz\xbe!\xa0\xdd\xb2?\xd9\xees\xad\xbb\r\xdb\xbf\xd8\xees\xad\xbb\r\xdb?\xf1\xabfO\xfa\xf3\xd8?\xf0\xabfO\xfa\xf3\xd8\xbf\xcf\x87\xf9\xb2c_\xf1?\xce\x87\xf9\xb2c_\xf1\xbf\x06\x947L\x0b\xac\xdf?\x07\x947L\x0b\xac\xdf\xbfQ8\xdc\xa0mu\xf3\xbfN8\xdc\xa0mu\xf3?\xf8\xc6=\x18\xb5\xdb\xe6?\xfa\xc6=\x18\xb5\xdb\xe6\xbf\xf8;>\x95\xca\xd2\xd8?\xf9;>\x95\xca\xd2\xd8\xbfO7.\x8e\xa6\x19\xf5?Q7.\x8e\xa6\x19\xf5\xbfO"\x86\xec#\x7f\xe9?K"\x86\xec#\x7f\xe9\xbf\xb1\xe3\xf4\xabV\x07\xf3?\xb0\xe3\xf4\xabV\x07\xf3\xbf\x91\xf8\xf6,|\x18\xb8?\x96\xf8\xf6,|\x18\xb8\xbf\x13\xdb\x1a\x89;\x10\xf1?\x15\xdb\x1a\x89;\x10\xf1\xbfh\x01\xec:\xef\xc5\xb3?z\x01\xec:\xef\xc5\xb3\xbf\xc9\x0b\xb6\x17E\xd0\xed\xbf\xc8\x0b\xb6\x17E\xd0\xed?\xbf\x1a\xc9V\x1e\x95\xe0?\xbd\x1a\xc9V\x1e\x95\xe0\xbf"\xbe!\xbf\xbd\x9d\xf5\xbf \xbe!\xbf\xbd\x9d\xf5?R\x1dq#(\xf7\xd7\xbfS\x1dq#(\xf7\xd7?\x86i\x9ff\xe2\x16\xe8?\x8ai\x9ff\xe2\x16\xe8\xbfQ\x80-\x16\xdc\xb1\xc6?V\x80-\x16\xdc\xb1\xc6\xbf\x1d\x84(\xf5\xc5\xf4\xd6\xbf \x84(\xf5\xc5\xf4\xd6?)\x9a\xbf\xe2F\xc5\xd9\xbf\'\x9a\xbf\xe2F\xc5\xd9?\xe1\x9d\xabn3\x0e\xa6\xbf\xd2\x9d\xabn3\x0e\xa6?\x11N\x17"\xbc(\xd3\xbf\x12N\x17"\xbc(\xd3?\x99UY2})\xe6\xbf\x9aUY2})\xe6?\xc8\xa2<\xe26]\xe8\xbf\xbb\xa2<\xe26]\xe8?\xfc\x18z\x0c\xdc:\xe2?\xfd\x18z\x0c\xdc:\xe2\xbf-a\xbf\xe1\xc3\x08\xe8\xbf+a\xbf\xe1\xc3\x08\xe8?\xa7w\xf6f\xf6\xcb\xd3?\xabw\xf6f\xf6\xcb\xd3\xbf\x04\xda]C&r\xde?\xff\xd9]C&r\xde\xbfX4\xd9\xf1O\x97\xe2?X4\xd9\xf1O\x97\xe2\xbf\x87\xd2\xa8\xa8z\xaa\xd3\xbf\x8f\xd2\xa8\xa8z\xaa\xd3?\xffR\x8c\xfen\x08\xe2\xbf\x00S\x8c\xfen\x08\xe2?\x9e\x07\x07\x17S;\xe4\xbf\x9e\x07\x07\x17S;\xe4?\xddR\x9e=\xab\xbd\xe9?\xdeR\x9e=\xab\xbd\xe9\xbf\xa7\xf3\xf8\xc2\x80t\xf1?\xa8\xf3\xf8\xc2\x80t\xf1\xbf23\xe9Ftt\xd6\xbf23\xe9Ftt\xd6?neF\xdc\xfb\x83\xe2?geF\xdc\xfb\x83\xe2\xbf\xbe]\x88\xd7*\xf5\xf0\xbf\xc0]\x88\xd7*\xf5\xf0?\xd3\xd9,7Nw\xd2\xbf\xce\xd9,7Nw\xd2?\x1e\xb3(\x91\x01\xcd\xc6?\x1f\xb3(\x91\x01\xcd\xc6\xbf\x9d\xf1\xd7\xd2m\xef\xa4\xbf\x9f\xf1\xd7\xd2m\xef\xa4?_\xe3\xd0\xb9\xb9\xc8\xdb?i\xe3\xd0\xb9\xb9\xc8\xdb\xbfr*#*\xab\x96\xe2?l*#*\xab\x96\xe2\xbf\xf9&\xa4\x96d\xe1\xe0?\xf7&\xa4\x96d\xe1\xe0\xbf\xbb\xff\xe1JLl\xea?\xbe\xff\xe1JLl\xea\xbf\xaex\x99\x82\xec\x1a\xe2?\xadx\x99\x82\xec\x1a\xe2\xbf3\xbf\xe3\xab]\x1b\xe0?4\xbf\xe3\xab]\x1b\xe0\xbfK\xdc\x04_\xf85\xf2?M\xdc\x04_\xf85\xf2\xbf\xc2,\xbc\xf9F<\xda\xbf\xc1,\xbc\xf9F<\xda?\x8e\xcfV\xd9\x92\x85\x87?\x86\xcfV\xd9\x92\x85\x87\xbf\xf0\x1d\x981\x03\xed\xda\xbf\xf8\x1d\x981\x03\xed\xda?\xe6\x92\x84\t\xe8\x9f\xea\xbf\xe3\x92\x84\t\xe8\x9f\xea?\xcd\x1a\x8d9\xfa\x88\xf1\xbf\xcd\x1a\x8d9\xfa\x88\xf1?\xc3I\xf1\xde6"\xb6?\xc0I\xf1\xde6"\xb6\xbf\xd7\x92\x1d=\xa40\x00\xc0\xd5\x92\x1d=\xa40\x00@qc\x00\x83>\xc5\xb7?\x85c\x00\x83>\xc5\xb7\xbf\x86Z\xd6\x12\x92P\xdb?\x81Z\xd6\x12\x92P\xdb\xbf\xd0\x10\xd7\xabX\xac\xe8?\xd1\x10\xd7\xabX\xac\xe8\xbfN\xb7\x00&\xf9\xca\xe8\xbfR\xb7\x00&\xf9\xca\xe8?rf?3\x89\x12\xe2\xbfrf?3\x89\x12\xe2?L\t\x05U\xd3\xdb\x94\xbfI\t\x05U\xd3\xdb\x94?\x93w\xf3@\x16%\xdc?\x89w\xf3@\x16%\xdc\xbf\xe8E\x07\x116\xba\xbd\xbf\xefE\x07\x116\xba\xbd?\x08"\xa7\xb8\xf0\xb0\xe3\xbf\x08"\xa7\xb8\xf0\xb0\xe3?L\xb9+M\xe6\xed\xd7\xbfI\xb9+M\xe6\xed\xd7?LOIy\xe3\x8e\xf4?MOIy\xe3\x8e\xf4\xbf\xc5\xdf\x9b\xa7\'Y\xef\xbf\xca\xdf\x9b\xa7\'Y\xef?\xc6z\x96\x14\xdb\x92\xd2\xbf\xc7z\x96\x14\xdb\x92\xd2?2\x86:\xc9;D\xb0\xbf+\x86:\xc9;D\xb0?[\xcb&{O\x85\xe5\xbfc\xcb&{O\x85\xe5?(P\xf2\x9c\x99^\xd7\xbf+P\xf2\x9c\x99^\xd7?\x0e\xb3\'\xa7\xca[\xb2\xbf\xfa\xb2\'\xa7\xca[\xb2?\xc8\x86\xf0\xa9\x0cd\xd7\xbf\xc4\x86\xf0\xa9\x0cd\xd7?\x91\xdd,\x9e\x0b\xca\x85?]\xdd,\x9e\x0b\xca\x85\xbfz\xea\xaf\x1f\xcb\x13\xf0?y\xea\xaf\x1f\xcb\x13\xf0\xbff\xb1\xbd\xbc\x96j\xec?e\xb1\xbd\xbc\x96j\xec\xbf\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x0e\x0b\x17\xb9"\x86\xe3\xbf\x0c\x0b\x17\xb9"\x86\xe3?s\xe5\x88Vm\x05\xdb\xbfl\xe5\x88Vm\x05\xdb?\xd2+\xa6\xbdZ\xae\xb4\xbf\xca+\xa6\xbdZ\xae\xb4?\x1e\x15\xe7q\x13\x19\xe3\xbf\x1d\x15\xe7q\x13\x19\xe3?\x08\xb6:|N\xd7\xe5?\x07\xb6:|N\xd7\xe5\xbf2\x83|>9\x80\xf5\xbf5\x83|>9\x80\xf5?e\xde\'\xa2\xffc\xe7\xbf_\xde\'\xa2\xffc\xe7?\xf7\xc8;\xda\xff\'\xa0?\xf8\xc8;\xda\xff\'\xa0\xbfY\xe0\xa3{\xca\xc6\xe5?Z\xe0\xa3{\xca\xc6\xe5\xbf[\xaf\x90\xe4\xac\xe1\xe6?]\xaf\x90\xe4\xac\xe1\xe6\xbf\x0f\xcbp\xf9\x06\xef\xea?\x14\xcbp\xf9\x06\xef\xea\xbf\xef\x1e\x07\xa1\x98p\xd7\xbf\xe6\x1e\x07\xa1\x98p\xd7?\x9f\xbf\xf6\xd2W\x93\xd0\xbf\x9d\xbf\xf6\xd2W\x93\xd0?6\xc3\xe5Q\x85\x1c\xe1?6\xc3\xe5Q\x85\x1c\xe1\xbf3\x91\x06\t\x97\x12\xd8?9\x91\x06\t\x97\x12\xd8\xbfD\xa7\xf0\x97\xfd\x19\xe3\xbfC\xa7\xf0\x97\xfd\x19\xe3?\xb0\xe6\x03R\x8e\xe4\xf9\xbf\xb1\xe6\x03R\x8e\xe4\xf9?\x8d\xeaG\x88_A\xf0\xbf\x8c\xeaG\x88_A\xf0?P\xe4\x90\xec\xf6\x10\xd0?G\xe4\x90\xec\xf6\x10\xd0\xbfR\xa4\x8eg\xa7\xb5\xd6?U\xa4\x8eg\xa7\xb5\xd6\xbf\xe1^yY+m\xb6?\xec^yY+m\xb6\xbf\x1d\x95\xc6p\xe8d\xe1\xbf#\x95\xc6p\xe8d\xe1?\x92\xae\x8aks\x8c\xf0?\x91\xae\x8aks\x8c\xf0\xbf\xe0\xf2-]\x953\xce\xbf\xdb\xf2-]\x953\xce?\xbf\x04\xc1\xcd\xa4\xfd\xed\xbf\xc4\x04\xc1\xcd\xa4\xfd\xed?\x13\x1e\x08BI\xe1\xf0\xbf\x14\x1e\x08BI\xe1\xf0?\xc5\x1cL\xef\xdb\x8f\xd1\xbf\xc4\x1cL\xef\xdb\x8f\xd1?Y\xe1\x98<\x0f_\xd1?b\xe1\x98<\x0f_\xd1\xbf\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00#\xc4\xf7@\xc1\xdb\xe5?$\xc4\xf7@\xc1\xdb\xe5\xbf\xd0\x8a\xb4\xe9\xf2y\xd7\xbf\xc2\x8a\xb4\xe9\xf2y\xd7?I\xef\xa1\xa7\x1a\xb6\xe0?J\xef\xa1\xa7\x1a\xb6\xe0\xbfs\xe8\x9d\x82{\x1c\xf2\xbfs\xe8\x9d\x82{\x1c\xf2?\xd4\xafd\xd5@\x8b\xea\xbf\xd5\xafd\xd5@\x8b\xea?;\xbcnE%\x19\xea?=\xbcnE%\x19\xea\xbf}\\\x81+>a\xf6?~\\\x81+>a\xf6\xbf\x04Y\xd6\xf0\xd5.\xc5\xbf\xf5X\xd6\xf0\xd5.\xc5? \x89<\xe3\x11\xda\xb3?)\x89<\xe3\x11\xda\xb3\xbf\x0b\xb4\x87\x18\xcd@\xd2\xbf\x13\xb4\x87\x18\xcd@\xd2?q/f\xa6\x19\x17\x01@p/f\xa6\x19\x17\x01\xc0\xac\xfa+\x9d\xc4\x88\xec\xbf\xad\xfa+\x9d\xc4\x88\xec?\xab\xceoq\x1dP\xd1?\xab\xceoq\x1dP\xd1\xbf)\xbfCOow\xe3? \xbfCOow\xe3\xbf\xed\xf2\x84>G\x1a\xc4?\xe9\xf2\x84>G\x1a\xc4\xbf`l\xdf\xc3Wh\xe1?bl\xdf\xc3Wh\xe1\xbf\x9a\xca\x07 \x12P\xd4?\x9d\xca\x07 \x12P\xd4\xbf\x9e\x00+>j\n\xf0\xbf\xa0\x00+>j\n\xf0?tF|\xb8u\xcb\xe0\xbftF|\xb8u\xcb\xe0?Ry\xf1.\'\x1c\x9d\xbf,y\xf1.\'\x1c\x9d?D\xdf\xd9\xdax\x17\xb3??\xdf\xd9\xdax\x17\xb3\xbfQ\xfe\x08\x97G\xb1\xe3?T\xfe\x08\x97G\xb1\xe3\xbfq|\x98%\x9d\xfb\xf1?s|\x98%\x9d\xfb\xf1\xbf\xce\x0e\xfd\xb3p\xc2\xeb\xbf\xca\x0e\xfd\xb3p\xc2\xeb?Q)\xb5\xb3RS\xe8\xbfM)\xb5\xb3RS\xe8?L!)\x05\xf0\xb5\xf6?L!)\x05\xf0\xb5\xf6\xbfl}0\xcc1R\xbe?n}0\xcc1R\xbe\xbf\x93\x1f\xc3\x0fHk\xfc\xbf\x92\x1f\xc3\x0fHk\xfc?Z\x9bH\xb21\x7f\xdf?^\x9bH\xb21\x7f\xdf\xbf\x8c\x9d\xc6E\xa0\x03\xa9\xbf0\x9d\xc6E\xa0\x03\xa9?\xb5\xda\x0b\x80"y\xfa\xbf\xb5\xda\x0b\x80"y\xfa?sJ\x9cA\x8a\x0f\xef?uJ\x9cA\x8a\x0f\xef\xbf\xf7\xec\xba\xe1\x93\x90\xe6?\xf8\xec\xba\xe1\x93\x90\xe6\xbff\x81>L\xff\xd1\xf1\xbfh\x81>L\xff\xd1\xf1?%\xdcM\x81[\xe9\xcf?#\xdcM\x81[\xe9\xcf\xbf\xe3IKC?|\xef\xbf\xe4IKC?|\xef?\xe9\xbd\x82\x86\xe8E\xb6?\xee\xbd\x82\x86\xe8E\xb6\xbf*\x12\x86\x7f\xe0\xd3\xf1?+\x12\x86\x7f\xe0\xd3\xf1\xbf\xb7j\x01\xf4\x16\x8b\x8d?\xadj\x01\xf4\x16\x8b\x8d\xbf\xbc\xc0\xf6\xe5\xbc\xce\xd2\xbf\xbe\xc0\xf6\xe5\xbc\xce\xd2?\x88D0\xf1\xa7\xc5\xd9\xbf\x82D0\xf1\xa7\xc5\xd9?\xe92&\xcb\xa3\xeb\xef?\xe72&\xcb\xa3\xeb\xef\xbf\x08~\xc5\x8cN\x89\xf3\xbf\n~\xc5\x8cN\x89\xf3?\\\x07\xca\x80t\xca\xad?{\x07\xca\x80t\xca\xad\xbf\x8a85Z\x87\xec\xf6?\x8c85Z\x87\xec\xf6\xbf\xf2\xd8j\x90d\x9c\xf1?\xf0\xd8j\x90d\x9c\xf1\xbf\x92\x15(W\x15Z\xca?\x92\x15(W\x15Z\xca\xbf\xb8w\x87a\xd8\xfb\xc5?\xb2w\x87a\xd8\xfb\xc5\xbf\xc0I1srI\xd2\xbf\xb7I1srI\xd2?_\xd6\x8f\t\xc5\x03\xcf?]\xd6\x8f\t\xc5\x03\xcf\xbf\x1b\xaaAY\x8e\xfc\xd5\xbf\x1e\xaaAY\x8e\xfc\xd5?\xaa\x90\x18\x1e\xe34\xd4?\xae\x90\x18\x1e\xe34\xd4\xbfH\xfbkl\xe2\x1d\xd4??\xfbkl\xe2\x1d\xd4\xbf \x90\xc6o\xaa&\xec?\x1f\x90\xc6o\xaa&\xec\xbf\x9c(\x1b\xcf\xf0#\xd3\xbf\x9a(\x1b\xcf\xf0#\xd3?\x8b\x8e\'a\x86M\xea\xbf\x8b\x8e\'a\x86M\xea?\xa0\xca\xe6\xfaV\xd4\xea?\xa1\xca\xe6\xfaV\xd4\xea\xbf\x96\x03\x92\xc2 \xdd\xe2?\x97\x03\x92\xc2 \xdd\xe2\xbf;7\xe6\x92h\xe5\xda\xbf@7\xe6\x92h\xe5\xda?\xce\xb3#3\xf6d\xa4?\xd0\xb3#3\xf6d\xa4\xbf\xcd\xa4p*\xb5\x9e\xe7\xbf\xce\xa4p*\xb5\x9e\xe7?\xdc\xa2\x9a\xcd\xd5\xe5\xf5\xbf\xd8\xa2\x9a\xcd\xd5\xe5\xf5?2\xd2o\xfec\x0e\x9c\xbf\xfa\xd1o\xfec\x0e\x9c?C\xdf\x99nq\xd9\xe6\xbf<\xdf\x99nq\xd9\xe6?{\x98\r\xc1\xd4\xa1\xdd\xbfz\x98\r\xc1\xd4\xa1\xdd?\xcf\x93\x84S\xde\xa0\xc9?\xc6\x93\x84S\xde\xa0\xc9\xbf\xe5:`\xc9\xe6j\xf5\xbf\xe2:`\xc9\xe6j\xf5?\xb4\xff\x82\x9f\xdeN\xb5\xbf\xaf\xff\x82\x9f\xdeN\xb5?N\xd4\x0c\xf0\xd2n\xe3\xbfQ\xd4\x0c\xf0\xd2n\xe3?\\\xc8\xfe\xf5\xa5\x9e\xe4?`\xc8\xfe\xf5\xa5\x9e\xe4\xbf\x1d\x8e\xefb:/\xe1\xbf\x1d\x8e\xefb:/\xe1?\xc4\xa7_\xd1\x03O\xe8?\xc1\xa7_\xd1\x03O\xe8\xbf\x13\xee4\xaap\x04\xdc?\x1f\xee4\xaap\x04\xdc\xbfr\xd7\xc0\x8d]\x97\xb0\xbf]\xd7\xc0\x8d]\x97\xb0?\xf4G\x13A9\x88\xdf\xbf\xfbG\x13A9\x88\xdf?\xbe\xa3=\x83\xac \xd2?\xc4\xa3=\x83\xac \xd2\xbf\xd1\x01\x06G\xf1\xeb\xf1?\xcf\x01\x06G\xf1\xeb\xf1\xbfV\x8b\xed\xd8\x8d\x03\xc3\xbfM\x8b\xed\xd8\x8d\x03\xc3?\x15~=\x18Ta\xea?\x19~=\x18Ta\xea\xbf\xb7\x05o\xe7\xbd@\xd2\xbf\xb5\x05o\xe7\xbd@\xd2?s\'\xce|\xf4\x0e\xdb?p\'\xce|\xf4\x0e\xdb\xbf\xef\x1f\xb8\xfb\xff\x98\xec?\xec\x1f\xb8\xfb\xff\x98\xec\xbf\xcf@\rt~L\xe1\xbf\xd1@\rt~L\xe1?\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x8d6\xb8\x07\xf7\x08\xf2?\x906\xb8\x07\xf7\x08\xf2\xbf\xf2\xd5Kit\xcb\xf0\xbf\xf0\xd5Kit\xcb\xf0?#\xf6\xe69\xd0k\x86\xbf\x19\xf6\xe69\xd0k\x86?2\x9e\xe9X\x9b\x97\xa5?5\x9e\xe9X\x9b\x97\xa5\xbf>\x99\xdb\x86\'5\xec\xbf>\x99\xdb\x86\'5\xec?'
tbasg39
I00
sg40
I00
sg41
g1
(g42
g3
NtRp137
(dp138
g45
(I00
I00
tp139
sg47
S'float64'
p140
sg49
g38
sg50
I00
sg31
Nsbsg51
Nsbsg31
S'W'
sg52
Nsg41
g137
sbasg12
(itheano.gof.utils
scratchpad
p141
(dp142
bsS'outputs'
p143
(lp144
g97
asS'op'
p145
g1
(ctheano.tensor.basic
Dot
p146
g3
NtRp147
(dp148
S'_op_use_c_code'
p149
S'/usr/bin/g++'
p150
sbsbsg41
g1
(g42
g3
NtRp151
(dp152
g45
(I00
I00
tp153
sg47
S'float64'
p154
sg49
g38
sg50
I00
sg31
Nsbsbag1
(g54
g3
NtRp155
(dp156
g9
S'auto_27'
p157
sg11
I0
sg12
(itheano.gof.utils
scratchpad
p158
(dp159
g15
(lp160
(lp161
(g18
I416
g19
S'sgd_optimization_mnist()'
tp162
a(g21
I243
g22
S'classifier = LogisticRegression(input=x, n_in=FEATURE_COUNT, n_out=2)'
tp163
a(g24
I73
g25
S'self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)'
tp164
aasbsg31
Nsg52
g1
(g66
g3
NtRp165
(dp166
g69
(lp167
g7
asg12
(itheano.gof.utils
scratchpad
p168
(dp169
bsg143
(lp170
g155
asg145
g1
(ctheano.tensor.elemwise
DimShuffle
p171
g3
NtRp172
(dp173
S'drop'
p174
(lp175
sS'shuffle'
p176
(lp177
I0
asS'augment'
p178
(lp179
I0
asS'input_broadcastable'
p180
g46
sS'inplace'
p181
I00
sS'new_order'
p182
(S'x'
I0
tp183
sg149
g150
sbsbsg41
g1
(g42
g3
NtRp184
(dp185
g45
(I01
I00
tp186
sg47
g48
sg49
g38
sg50
I00
sg31
Nsbsbasg12
(itheano.gof.utils
scratchpad
p187
(dp188
bsg143
(lp189
g84
asg145
g1
(ctheano.tensor.elemwise
Elemwise
p190
g3
NtRp191
(dp192
S'__module__'
p193
S'tensor'
p194
sS'scalar_op'
p195
g1
(ctheano.scalar.basic
Add
p196
g3
NtRp197
(dp198
S'output_types_preference'
p199
ctheano.scalar.basic
upcast_out
p200
sg149
g150
sg31
S'add'
p201
sbsg31
S'Elemwise{add,no_inplace}'
p202
sg149
g150
sS'destroy_map'
p203
(dp204
sS'nfunc_spec'
p205
(S'add'
I2
I1
tp206
sS'inplace_pattern'
p207
(dp208
sS'openmp'
p209
I00
sS'__doc__'
p210
S"elementwise addition\n\n    Generalizes a scalar op to tensors.\n\n    All the inputs must have the same number of dimensions. When the\n    Op is performed, for each dimension, each input's size for that\n    dimension must be the same. As a special case, it can also be 1\n    but only if the input's broadcastable flag is True for that\n    dimension. In that case, the tensor is (virtually) replicated\n    along that dimension to match the size of the others.\n\n    The dtypes of the outputs mirror those of the scalar Op that is\n    being generalized to tensors. In particular, if the calculations\n    for an output are done inplace on an input, the output type must\n    be the same as the corresponding input type (see the doc of\n    scalar.ScalarOp to get help about controlling the output type)\n\n    Parameters\n    ----------\n    scalar_op\n        An instance of a subclass of scalar.ScalarOp which works uniquely\n        on scalars.\n    inplace_pattern\n        A dictionary that maps the index of an output to the\n        index of an input so the output is calculated inplace using\n        the input's storage. (Just like destroymap, but without the lists.)\n    nfunc_spec\n        Either None or a tuple of three elements,\n        (nfunc_name, nin, nout) such that getattr(numpy, nfunc_name)\n        implements this operation, takes nin inputs and nout outputs.\n        Note that nin cannot always be inferred from the scalar op's\n        own nin field because that value is sometimes 0 (meaning a\n        variable number of inputs), whereas the numpy function may\n        not have varargs.\n\n    Note\n    ----\n    | Elemwise(add) represents + on tensors (x + y)\n    | Elemwise(add, {0 : 0}) represents the += operation (x += y)\n    | Elemwise(add, {0 : 1}) represents += on the second argument (y += x)\n    | Elemwise(mul)(rand(10, 5), rand(1, 5)) the second input is completed along the first dimension to match the first input\n    | Elemwise(true_div)(rand(10, 5), rand(10, 1)) same but along the second dimension\n    | Elemwise(int_div)(rand(1, 5), rand(10, 1)) the output has size (10, 5)\n    | Elemwise(log)(rand(3, 4, 5))\n\n    "
p211
sbsbsg41
g1
(g42
g3
NtRp212
(dp213
g45
(I00
I00
tp214
sg47
S'float64'
p215
sg49
g38
sg50
I00
sg31
Nsbsbasg12
(itheano.gof.utils
scratchpad
p216
(dp217
bsg143
(lp218
g71
asg145
g1
(ctheano.tensor.nnet.nnet
Softmax
p219
g3
NtRp220
(dp221
g149
g150
sbsbsg41
g212
sbag1
(ctheano.tensor.var
TensorConstant
p222
g3
NtRp223
(dp224
g9
S'auto_30'
p225
sg11
Nsg12
(itheano.gof.utils
scratchpad
p226
(dp227
S'unique_value'
p228
cnumpy.core.multiarray
scalar
p229
(g37
(S'i8'
I0
I1
tRp230
(I3
S'<'
NNNI-1
I-1
I0
tbS'\x01\x00\x00\x00\x00\x00\x00\x00'
tRp231
sbsg31
NsS'cached'
p232
I01
sg41
g1
(g42
g3
NtRp233
(dp234
g45
(I01
tp235
sg47
S'int64'
p236
sg49
g230
sg50
I00
sg31
NsbsS'data'
p237
g34
(g35
(I0
tS'b'
tRp238
(I1
(I1
tg230
I00
S'\x01\x00\x00\x00\x00\x00\x00\x00'
tbsbasg12
(itheano.gof.utils
scratchpad
p239
(dp240
bsg143
(lp241
g1
(g54
g3
NtRp242
(dp243
g9
S'auto_31'
p244
sg11
I0
sg12
(itheano.gof.utils
scratchpad
p245
(dp246
g15
(lp247
(lp248
(g18
I416
g19
S'sgd_optimization_mnist()'
tp249
a(g21
I243
g22
S'classifier = LogisticRegression(input=x, n_in=FEATURE_COUNT, n_out=2)'
tp250
a(g24
I77
g25
S'self.y_pred = T.argmax(self.p_y_given_x, axis=1)'
tp251
aasbsg31
S'max'
p252
sg52
g67
sg41
g1
(g42
g3
NtRp253
(dp254
g45
(I00
tp255
sg47
g215
sg49
g38
sg50
I00
sg31
Nsbsbag55
asg145
g1
(ctheano.tensor.basic
MaxAndArgmax
p256
g3
NtRp257
(dp258
g149
g150
sbsbsg41
g1
(g42
g3
NtRp259
(dp260
g45
(I00
tp261
sg47
S'int64'
p262
sg49
g230
sg50
I00
sg31
NsbsbsS'params'
p263
(lp264
g123
ag7
asS'W'
g123
sS'input'
p265
g110
sS'p_y_given_x'
p266
g71
sb.